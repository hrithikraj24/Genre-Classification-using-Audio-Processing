{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler ,MinMaxScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1497, 51)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_var</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_var</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>mean_spectral_rolloff</th>\n",
       "      <th>var_spectral_rolloff</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>chroma_deviation_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000_1.wav</td>\n",
       "      <td>0.078317</td>\n",
       "      <td>0.013519</td>\n",
       "      <td>0.124483</td>\n",
       "      <td>0.056088</td>\n",
       "      <td>1782.622682</td>\n",
       "      <td>3845.075667</td>\n",
       "      <td>912.603923</td>\n",
       "      <td>2020.556328</td>\n",
       "      <td>0.342053</td>\n",
       "      <td>...</td>\n",
       "      <td>8.364929</td>\n",
       "      <td>-2.870996</td>\n",
       "      <td>5.956472</td>\n",
       "      <td>0.306078</td>\n",
       "      <td>6.595972</td>\n",
       "      <td>-2.700369</td>\n",
       "      <td>7.661201</td>\n",
       "      <td>2.370232</td>\n",
       "      <td>6.931646</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00000_2.wav</td>\n",
       "      <td>0.079108</td>\n",
       "      <td>0.015145</td>\n",
       "      <td>0.135369</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>1803.133844</td>\n",
       "      <td>3903.829836</td>\n",
       "      <td>1059.169428</td>\n",
       "      <td>2043.208033</td>\n",
       "      <td>0.366391</td>\n",
       "      <td>...</td>\n",
       "      <td>6.095594</td>\n",
       "      <td>-0.946113</td>\n",
       "      <td>6.237660</td>\n",
       "      <td>-0.170836</td>\n",
       "      <td>6.636129</td>\n",
       "      <td>-2.291198</td>\n",
       "      <td>6.289830</td>\n",
       "      <td>1.508931</td>\n",
       "      <td>5.563946</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00000_3.wav</td>\n",
       "      <td>0.085122</td>\n",
       "      <td>0.017463</td>\n",
       "      <td>0.130891</td>\n",
       "      <td>0.049173</td>\n",
       "      <td>1767.406536</td>\n",
       "      <td>3672.610197</td>\n",
       "      <td>846.426470</td>\n",
       "      <td>1944.426261</td>\n",
       "      <td>0.341613</td>\n",
       "      <td>...</td>\n",
       "      <td>7.039822</td>\n",
       "      <td>-2.871219</td>\n",
       "      <td>5.890341</td>\n",
       "      <td>0.118136</td>\n",
       "      <td>6.060444</td>\n",
       "      <td>-3.230836</td>\n",
       "      <td>8.228865</td>\n",
       "      <td>0.995681</td>\n",
       "      <td>7.727270</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00001_1.wav</td>\n",
       "      <td>0.054409</td>\n",
       "      <td>0.028735</td>\n",
       "      <td>0.094405</td>\n",
       "      <td>0.048287</td>\n",
       "      <td>1364.273766</td>\n",
       "      <td>2976.303348</td>\n",
       "      <td>1565.934901</td>\n",
       "      <td>1842.030467</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.924546</td>\n",
       "      <td>0.497852</td>\n",
       "      <td>7.825360</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>6.962971</td>\n",
       "      <td>-1.083576</td>\n",
       "      <td>7.379338</td>\n",
       "      <td>-0.112309</td>\n",
       "      <td>7.344995</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00001_2.wav</td>\n",
       "      <td>0.051896</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0.087959</td>\n",
       "      <td>0.045535</td>\n",
       "      <td>1581.277785</td>\n",
       "      <td>3786.371459</td>\n",
       "      <td>1798.029729</td>\n",
       "      <td>2125.234003</td>\n",
       "      <td>0.346125</td>\n",
       "      <td>...</td>\n",
       "      <td>7.415159</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>7.570110</td>\n",
       "      <td>-0.367247</td>\n",
       "      <td>6.951124</td>\n",
       "      <td>-2.646990</td>\n",
       "      <td>6.376883</td>\n",
       "      <td>1.118412</td>\n",
       "      <td>6.769454</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  zcr_mean   zcr_var  rmse_mean  rmse_var  \\\n",
       "0  blues.00000_1.wav  0.078317  0.013519   0.124483  0.056088   \n",
       "1  blues.00000_2.wav  0.079108  0.015145   0.135369  0.053363   \n",
       "2  blues.00000_3.wav  0.085122  0.017463   0.130891  0.049173   \n",
       "3  blues.00001_1.wav  0.054409  0.028735   0.094405  0.048287   \n",
       "4  blues.00001_2.wav  0.051896  0.017981   0.087959  0.045535   \n",
       "\n",
       "   spectral_centroid  mean_spectral_rolloff  var_spectral_rolloff  \\\n",
       "0        1782.622682            3845.075667            912.603923   \n",
       "1        1803.133844            3903.829836           1059.169428   \n",
       "2        1767.406536            3672.610197            846.426470   \n",
       "3        1364.273766            2976.303348           1565.934901   \n",
       "4        1581.277785            3786.371459           1798.029729   \n",
       "\n",
       "   spectral_bandwidth  chroma_deviation_mean  ...  mfcc16_var  mfcc17_mean  \\\n",
       "0         2020.556328               0.342053  ...    8.364929    -2.870996   \n",
       "1         2043.208033               0.366391  ...    6.095594    -0.946113   \n",
       "2         1944.426261               0.341613  ...    7.039822    -2.871219   \n",
       "3         1842.030467               0.358000  ...    7.924546     0.497852   \n",
       "4         2125.234003               0.346125  ...    7.415159     0.114600   \n",
       "\n",
       "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n",
       "0    5.956472     0.306078    6.595972    -2.700369    7.661201     2.370232   \n",
       "1    6.237660    -0.170836    6.636129    -2.291198    6.289830     1.508931   \n",
       "2    5.890341     0.118136    6.060444    -3.230836    8.228865     0.995681   \n",
       "3    7.825360     0.039326    6.962971    -1.083576    7.379338    -0.112309   \n",
       "4    7.570110    -0.367247    6.951124    -2.646990    6.376883     1.118412   \n",
       "\n",
       "   mfcc20_var  genre  \n",
       "0    6.931646  blues  \n",
       "1    5.563946  blues  \n",
       "2    7.727270  blues  \n",
       "3    7.344995  blues  \n",
       "4    6.769454  blues  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data preprocessing: It involves loading CSV data, label encoding, feature scaling and data split into training and test set.\n",
    "# loading CSV data\n",
    "data = pd.read_csv('mycsv_35_new5genre.csv') \n",
    "print(data.shape)\n",
    "data.describe()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>zcr_var</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_var</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>mean_spectral_rolloff</th>\n",
       "      <th>var_spectral_rolloff</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>chroma_deviation_mean</th>\n",
       "      <th>mfcc1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078317</td>\n",
       "      <td>0.013519</td>\n",
       "      <td>0.124483</td>\n",
       "      <td>0.056088</td>\n",
       "      <td>1782.622682</td>\n",
       "      <td>3845.075667</td>\n",
       "      <td>912.603923</td>\n",
       "      <td>2020.556328</td>\n",
       "      <td>0.342053</td>\n",
       "      <td>-125.188171</td>\n",
       "      <td>...</td>\n",
       "      <td>8.364929</td>\n",
       "      <td>-2.870996</td>\n",
       "      <td>5.956472</td>\n",
       "      <td>0.306078</td>\n",
       "      <td>6.595972</td>\n",
       "      <td>-2.700369</td>\n",
       "      <td>7.661201</td>\n",
       "      <td>2.370232</td>\n",
       "      <td>6.931646</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079108</td>\n",
       "      <td>0.015145</td>\n",
       "      <td>0.135369</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>1803.133844</td>\n",
       "      <td>3903.829836</td>\n",
       "      <td>1059.169428</td>\n",
       "      <td>2043.208033</td>\n",
       "      <td>0.366391</td>\n",
       "      <td>-104.649918</td>\n",
       "      <td>...</td>\n",
       "      <td>6.095594</td>\n",
       "      <td>-0.946113</td>\n",
       "      <td>6.237660</td>\n",
       "      <td>-0.170836</td>\n",
       "      <td>6.636129</td>\n",
       "      <td>-2.291198</td>\n",
       "      <td>6.289830</td>\n",
       "      <td>1.508931</td>\n",
       "      <td>5.563946</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085122</td>\n",
       "      <td>0.017463</td>\n",
       "      <td>0.130891</td>\n",
       "      <td>0.049173</td>\n",
       "      <td>1767.406536</td>\n",
       "      <td>3672.610197</td>\n",
       "      <td>846.426470</td>\n",
       "      <td>1944.426261</td>\n",
       "      <td>0.341613</td>\n",
       "      <td>-112.962753</td>\n",
       "      <td>...</td>\n",
       "      <td>7.039822</td>\n",
       "      <td>-2.871219</td>\n",
       "      <td>5.890341</td>\n",
       "      <td>0.118136</td>\n",
       "      <td>6.060444</td>\n",
       "      <td>-3.230836</td>\n",
       "      <td>8.228865</td>\n",
       "      <td>0.995681</td>\n",
       "      <td>7.727270</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054409</td>\n",
       "      <td>0.028735</td>\n",
       "      <td>0.094405</td>\n",
       "      <td>0.048287</td>\n",
       "      <td>1364.273766</td>\n",
       "      <td>2976.303348</td>\n",
       "      <td>1565.934901</td>\n",
       "      <td>1842.030467</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>-221.931198</td>\n",
       "      <td>...</td>\n",
       "      <td>7.924546</td>\n",
       "      <td>0.497852</td>\n",
       "      <td>7.825360</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>6.962971</td>\n",
       "      <td>-1.083576</td>\n",
       "      <td>7.379338</td>\n",
       "      <td>-0.112309</td>\n",
       "      <td>7.344995</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051896</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0.087959</td>\n",
       "      <td>0.045535</td>\n",
       "      <td>1581.277785</td>\n",
       "      <td>3786.371459</td>\n",
       "      <td>1798.029729</td>\n",
       "      <td>2125.234003</td>\n",
       "      <td>0.346125</td>\n",
       "      <td>-222.168320</td>\n",
       "      <td>...</td>\n",
       "      <td>7.415159</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>7.570110</td>\n",
       "      <td>-0.367247</td>\n",
       "      <td>6.951124</td>\n",
       "      <td>-2.646990</td>\n",
       "      <td>6.376883</td>\n",
       "      <td>1.118412</td>\n",
       "      <td>6.769454</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zcr_mean   zcr_var  rmse_mean  rmse_var  spectral_centroid  \\\n",
       "0  0.078317  0.013519   0.124483  0.056088        1782.622682   \n",
       "1  0.079108  0.015145   0.135369  0.053363        1803.133844   \n",
       "2  0.085122  0.017463   0.130891  0.049173        1767.406536   \n",
       "3  0.054409  0.028735   0.094405  0.048287        1364.273766   \n",
       "4  0.051896  0.017981   0.087959  0.045535        1581.277785   \n",
       "\n",
       "   mean_spectral_rolloff  var_spectral_rolloff  spectral_bandwidth  \\\n",
       "0            3845.075667            912.603923         2020.556328   \n",
       "1            3903.829836           1059.169428         2043.208033   \n",
       "2            3672.610197            846.426470         1944.426261   \n",
       "3            2976.303348           1565.934901         1842.030467   \n",
       "4            3786.371459           1798.029729         2125.234003   \n",
       "\n",
       "   chroma_deviation_mean  mfcc1_mean  ...  mfcc16_var  mfcc17_mean  \\\n",
       "0               0.342053 -125.188171  ...    8.364929    -2.870996   \n",
       "1               0.366391 -104.649918  ...    6.095594    -0.946113   \n",
       "2               0.341613 -112.962753  ...    7.039822    -2.871219   \n",
       "3               0.358000 -221.931198  ...    7.924546     0.497852   \n",
       "4               0.346125 -222.168320  ...    7.415159     0.114600   \n",
       "\n",
       "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n",
       "0    5.956472     0.306078    6.595972    -2.700369    7.661201     2.370232   \n",
       "1    6.237660    -0.170836    6.636129    -2.291198    6.289830     1.508931   \n",
       "2    5.890341     0.118136    6.060444    -3.230836    8.228865     0.995681   \n",
       "3    7.825360     0.039326    6.962971    -1.083576    7.379338    -0.112309   \n",
       "4    7.570110    -0.367247    6.951124    -2.646990    6.376883     1.118412   \n",
       "\n",
       "   mfcc20_var  genre  \n",
       "0    6.931646  blues  \n",
       "1    5.563946  blues  \n",
       "2    7.727270  blues  \n",
       "3    7.344995  blues  \n",
       "4    6.769454  blues  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping unnecessary columns\n",
    "dataset = data.drop(['filename'],axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label encoding\n",
    "encode = LabelEncoder().fit(dataset.iloc[:,-1])\n",
    "y= LabelEncoder().fit_transform(dataset.iloc[:,-1]) #feature scaling\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1497, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(np.array(dataset.iloc[:, :-15], dtype = float))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (1047, 35) (1047,)\n",
      "Test set: (450, 35) (450,)\n"
     ]
    }
   ],
   "source": [
    "#Creating training and testing data set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=42)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our regression model \n",
    "n_cols = dataset.iloc[:, :-15].shape[1]\n",
    "def regression_model_1():\n",
    "    # structure of our model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(5,activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               9216      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,533\n",
      "Trainable params: 53,573\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=10, \n",
    "                                            verbose=1, \n",
    "                                            )\n",
    "Callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 19s 59ms/step - loss: 1.4599 - accuracy: 0.4059 - val_loss: 1.3092 - val_accuracy: 0.6222 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.9207 - accuracy: 0.6409 - val_loss: 1.0666 - val_accuracy: 0.7644 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.7429 - accuracy: 0.7278 - val_loss: 0.8790 - val_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.6115 - accuracy: 0.7822 - val_loss: 0.7186 - val_accuracy: 0.8578 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.8262 - val_loss: 0.6083 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.4920 - accuracy: 0.8243 - val_loss: 0.5161 - val_accuracy: 0.8622 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8730 - val_loss: 0.4427 - val_accuracy: 0.8756 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8606 - val_loss: 0.3983 - val_accuracy: 0.8844 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8682 - val_loss: 0.3477 - val_accuracy: 0.8822 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3382 - accuracy: 0.8758 - val_loss: 0.3331 - val_accuracy: 0.8756 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.3022 - accuracy: 0.9054 - val_loss: 0.3231 - val_accuracy: 0.8756 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8892 - val_loss: 0.2944 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2901 - accuracy: 0.9064 - val_loss: 0.2682 - val_accuracy: 0.9089 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2593 - accuracy: 0.9169 - val_loss: 0.2722 - val_accuracy: 0.9044 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2323 - accuracy: 0.9179 - val_loss: 0.2638 - val_accuracy: 0.9067 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2185 - accuracy: 0.9389 - val_loss: 0.2561 - val_accuracy: 0.9067 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.2066 - accuracy: 0.9322 - val_loss: 0.2509 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2053 - accuracy: 0.9370 - val_loss: 0.2498 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1789 - accuracy: 0.9484 - val_loss: 0.2521 - val_accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.2016 - accuracy: 0.9322 - val_loss: 0.2578 - val_accuracy: 0.9044 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1725 - accuracy: 0.9436 - val_loss: 0.2695 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1707 - accuracy: 0.9465 - val_loss: 0.2650 - val_accuracy: 0.9044 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1456 - accuracy: 0.9513 - val_loss: 0.2452 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.9522 - val_loss: 0.2526 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1282 - accuracy: 0.9637 - val_loss: 0.2586 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.1611 - accuracy: 0.9522 - val_loss: 0.2636 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1153 - accuracy: 0.9599 - val_loss: 0.2381 - val_accuracy: 0.9356 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9570 - val_loss: 0.2326 - val_accuracy: 0.9311 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.9713 - val_loss: 0.2693 - val_accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.1321 - accuracy: 0.9589 - val_loss: 0.2588 - val_accuracy: 0.9222 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.1281 - accuracy: 0.9532 - val_loss: 0.2335 - val_accuracy: 0.9222 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9580 - val_loss: 0.2518 - val_accuracy: 0.9244 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.1108 - accuracy: 0.9666 - val_loss: 0.2713 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.1116 - accuracy: 0.9608 - val_loss: 0.2801 - val_accuracy: 0.9200 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9723 - val_loss: 0.2701 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9761 - val_loss: 0.2635 - val_accuracy: 0.9178 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "13/21 [=================>............] - ETA: 0s - loss: 0.1077 - accuracy: 0.9677\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.1123 - accuracy: 0.9589 - val_loss: 0.2710 - val_accuracy: 0.9244 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9694 - val_loss: 0.2591 - val_accuracy: 0.9244 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20ec9a59bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build the model\n",
    "model_1 = regression_model_1()\n",
    "\n",
    "#fit the model\n",
    "#model_1.fit(X_train,y_train,epochs=100,batch_size=150)\n",
    "model_1.fit(X_train,y_train, callbacks=Callbacks , validation_data=(X_test,y_test) ,epochs=100,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_1.save('Keras_reg_30sec_5.h5')\n",
    "#model_1.save('Keras_reg_30sec_5_35.h5')\n",
    "#model_1.save('Keras_reg_30sec_5_31_chroma.h5')\n",
    "#model_1.save('Keras_reg_30sec_5_35+chroma.h5')\n",
    "#model_1.save('Keras_reg_30sec_new5_35+chroma.h5')\n",
    "#model_1.save('Keras_reg_30sec_new5_35(1).h5')\n",
    "#model_1.save('Keras_reg_30sec_10_35.h5') \n",
    "\n",
    "#1st combination\n",
    "model_1.save('Keras_reg_30sec_new5_35_as.h5') \n",
    "#model_1.save('Keras_reg_30sec_new5_35+chroma_as.h5')\n",
    "\n",
    "#2nd combination\n",
    "#model_1.save('Keras_reg_30sec_new5_35_as(1).h5')\n",
    "#model_1.save('Keras_reg_30sec_new5_35+chroma_as(1).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 92.44%\n"
     ]
    }
   ],
   "source": [
    "#model = load_model('Keras_reg_30sec_5_35.h5')\n",
    "model = load_model('Keras_reg_30sec_new5_35_as.h5')\n",
    "score = model.evaluate(X_test,y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 4 4 2 2 2 2 1 0 2 3 4 4 0 0 2 3 1 0 1 1 0 4 1 1 4 4 4 2 0 1 2 4 2 2 1\n",
      " 1 1 0 1 2 3 4 1 1 3 1 1 1 3 3 1 2 1 2 0 4 0 4 3 3 4 0 2 1 1 4 4 2 3 3 2 1\n",
      " 3 1 1 2 2 1 3 0 0 2 0 0 3 4 2 2 3 1 3 3 0 3 1 0 1 3 2 2 2 1 4 0 0 0 0 2 1\n",
      " 4 2 1 0 1 2 4 0 3 2 1 2 2 0 3 2 2 2 0 0 0 1 3 1 0 3 1 3 0 1 0 4 3 0 1 2 4\n",
      " 2 4 3 3 1 1 2 4 1 2 0 1 3 0 1 0 0 4 4 2 1 2 3 1 3 0 2 1 3 1 2 2 3 0 4 2 2\n",
      " 3 4 1 1 0 4 2 4 4 0 4 0 2 3 3 3 1 4 3 3 0 3 1 1 0 2 3 3 3 4 1 2 4 0 0 4 3\n",
      " 3 0 4 4 0 4 4 1 1 3 1 3 2 4 4 4 2 2 2 3 0 2 2 3 4 3 0 3 2 2 3 1 4 3 3 3 3\n",
      " 0 0 4 3 4 3 1 0 1 3 4 0 1 2 3 2 3 4 3 3 2 4 2 4 0 3 0 4 0 4 2 4 0 4 4 3 1\n",
      " 4 3 4 1 3 4 3 1 3 4 4 3 2 1 1 1 4 4 3 2 2 0 3 1 4 3 4 1 4 0 4 0 0 4 1 3 1\n",
      " 1 3 0 0 1 1 2 1 2 3 3 4 0 3 2 2 4 2 0 3 3 2 1 3 1 0 1 3 1 0 4 3 0 2 0 2 4\n",
      " 4 1 4 2 2 2 2 0 1 1 4 2 3 1 3 3 1 1 3 1 1 1 2 0 3 1 4 2 4 4 4 1 1 1 1 0 2\n",
      " 3 1 3 0 2 3 0 4 2 4 0 2 0 1 3 3 3 1 0 4 4 0 1 0 3 3 3 1 0 2 2 3 0 3 0 4 2\n",
      " 4 4 4 1 4 0]\n",
      "[3 4 4 4 2 2 3 2 1 0 2 3 4 4 0 0 2 3 1 0 1 1 0 4 1 1 4 4 4 2 0 1 2 4 3 2 1\n",
      " 1 1 0 1 2 3 4 4 1 3 1 1 4 3 3 1 3 1 2 0 4 0 4 3 3 4 0 2 1 1 4 4 4 3 3 2 1\n",
      " 3 1 1 2 2 1 3 0 0 2 0 0 3 4 2 2 3 1 3 3 3 3 1 0 1 3 0 2 2 2 4 0 0 0 0 2 1\n",
      " 4 2 1 0 1 2 4 0 3 2 1 2 2 0 3 2 2 2 0 0 0 1 3 1 0 3 1 3 0 1 0 4 3 0 1 2 4\n",
      " 2 4 3 3 1 1 2 4 1 2 0 1 3 0 1 0 0 1 4 2 1 2 3 1 3 0 2 1 3 1 2 0 3 4 0 2 2\n",
      " 3 4 1 1 0 4 4 4 4 0 4 0 0 3 3 3 1 4 3 3 0 3 1 1 0 2 3 3 3 4 1 3 4 0 0 4 3\n",
      " 3 0 4 0 0 4 4 1 1 3 1 3 2 4 4 4 2 2 2 3 0 2 2 3 4 3 3 3 2 2 3 1 4 3 3 3 3\n",
      " 3 0 4 3 4 3 1 0 1 3 4 0 1 2 3 2 2 4 3 3 2 4 2 4 0 3 0 4 0 4 2 4 0 4 4 3 1\n",
      " 4 3 4 1 3 4 3 1 3 4 4 3 2 1 1 1 4 4 3 2 2 0 3 4 4 3 4 1 4 0 4 0 0 4 1 3 1\n",
      " 1 3 0 0 1 1 0 1 2 3 3 4 0 3 2 4 0 2 0 3 3 2 1 3 1 0 1 3 1 2 4 3 0 2 0 0 4\n",
      " 4 1 4 2 4 4 2 0 1 4 2 2 3 1 3 3 1 1 3 1 1 1 2 0 3 1 4 2 4 4 4 1 4 1 1 0 2\n",
      " 3 1 3 0 2 3 0 4 2 4 0 2 0 1 3 3 3 1 0 4 4 0 1 0 3 3 3 1 0 2 2 3 0 3 0 4 3\n",
      " 2 4 4 1 4 0]\n"
     ]
    }
   ],
   "source": [
    "#predictions = model.predict_classes(X_test)\n",
    "predict_x=model.predict(X_test) \n",
    "predictions=np.argmax(predict_x,axis=1)\n",
    "print(predictions)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76  0  5  0  3]\n",
      " [ 0 91  0  0  1]\n",
      " [ 1  1 71  1  2]\n",
      " [ 3  0  6 96  0]\n",
      " [ 1  5  5  0 82]]\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test,predictions)\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5, 1.5, 2.5, 3.5, 4.5]),\n",
       " [Text(0, 0.5, 'blues'),\n",
       "  Text(0, 1.5, 'classical'),\n",
       "  Text(0, 2.5, 'country'),\n",
       "  Text(0, 3.5, 'hiphop'),\n",
       "  Text(0, 4.5, 'jazz')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAGbCAYAAACh0BXiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtOUlEQVR4nO3deXxU9fX/8ddJQgoBAaMQURAQaF1wK7iDLO47KC5VK1o17svXal2/lrr9tFqtrbaKtsC3Ll8VFNdaLUJBtAgICIhWKogIBBCVNZJMzu+PudzMNw2EZXJvbub95DGPzF3m3vPJneTknPnMYO6OiIhIUuXFHYCIiMi2UCITEZFEUyITEZFEUyITEZFEUyITEZFEK4g7gIhoaqaINFaWzYM12//KrP2+XDftkazGtjG5ksjY+ZIX4w4hcoseP5XyyrijiEfTAlixJhV3GJErbp6f09d8ZXlV3GFErmVTNdZyJpGJiMhmsOQlRiUyERGpZpF0A7MqealXREQkgyoyERGpptaiiIgkmlqLIiIi0VJFJiIi1dRaFBGRRFNrUUREJFqqyEREpJpaiyIikmhqLYqIiERLFZmIiFRTa1FERBJNrUUREZFoqSITEZFqai2KiEiiqbUoIiISLVVkIiJSTa1FERFJtAQmsuRFLCIikkEVmYiIVMtL3mQPJTIREamm1qKIiEi0VJGJiEi1BL6PTIlMRESqqbUoIiISLVVkIiJSTa1FERFJtAS2FpXIRESkWgIrsuSlXhERkQyqyEREpJpai7mrS0kLHrv4wHB51x2bc/+rH/PkmH/zs367cX7fLqSqnDEzl3DXi7NijLT+TZwwnvvuvZuqVBUDTzudCy8ujTukSAw84UiKmjcnPy+P/PwChj39QtwhRSYXr/n3339P6QU/paJiPZWVlRxx1DFccvlVcYe17RLYWqz3RGZmnYDX3L17jfXjgOvdfUp9xxCFf5et5qi73gHSH1X24X3H89dpizj0hztyzL47c+SdY1hfWcUO2/0g5kjrVyqV4p677+DxJ4ZRUlLC2WcOom+//nTp2jXu0CLx6OPDab399nGHEalcveaFhYX88clhFBU1p7KigovOP5dDe/Vm7332izu0nJO8GjIBeu/eli+WreGrFes4r89uPPLmp6yvrALg61Xfxxxd/Zo18yM6dOhI+w4daFJYyLHHn8C4sWPiDkvqUa5eczOjqKg5AJWVlVRWVmAkr5r5D5aXvVtEojpTgZk9bWZzzGykmRVlbjSz1Rn3B5nZ8OB+GzMbZWaTg9thwfo+ZjY9uE0zs+0iGsdmOeWA9oye/CWQbjke1G1HXrupL6N+3pt9Ozbuv9aXlpWxU7udwuW2JSWUlZXFGFF0zIxrrriI888exOhRz8cdTmRy+ZqnUinOPmMgR/frxUEHH0r3ffaNO6RtZ5a9W0SiSmQ/Av7g7nsAK4HLN/NxDwMPufsBwGnAk8H664Er3H0/oDewruYDzazUzKaY2ZShQ4dua/ybrUm+cfS+7Xh16lcA5OcZrZsXcuK947hz1CweLz2wjiNIUj3256cY8cwoHnzkcUY9/yzTpjaKrrlsQn5+Ps88/xKvvzWW2bNmMvezf8UdUk6KKpF96e4Tg/tPAb0283FHAo+Y2XTgFaClmbUAJgIPmtnVQGt3r6z5QHcf6u493b1naWl0Lzz3774TMxd8y/Kghbj423Le+DCd1KbP/4Yqd4pbFEYWT9TalpSwZPGScHlpWRklJSUxRhSdtm3T4ywu3oE+/Y7g49kfxRxRNHL5mm+wXcuW9DjgQN5/7924Q9l2ai1ulG/BctOM+3nAwe6+X3Dbxd1Xu/u9wEVAM2Cime2e/ZC3zoAD2jN68sJw+c3pizjsR20A2K1tCwrz81ixen1c4dW7vbrvzYIF81m48Esq1q/nzTdep0+//nGHVe/WrVvLmjVrwvuT/vkeu3XpFnNU0cjVa/7NihWsWrkSgPLycj745/t06tQ55qiyIIGJLKrp97ua2SHu/j5wNvAucFLG9jIz2wP4FBgIrArWvwVcBdwPYGb7uft0M+vi7jOBmWZ2ALA78ElEY9moZoX59N6jLb94alq47n8nzufBwT145/YjqEg51wyfGmOE9a+goICbb72dy0ovoqoqxYCBp9G1a+P/hb7i66+56edXA5BKVXL0sSdwyGG9Y44qGrl6zZcvX8aQ226mqipFVVUVRx59LL379Is7rJxk7jWLoyyfID39/k1gCtAD+Bj4KfAGwfR7MxsE3AcsC/Zr4e7nm9mOwKPAHqST7nh3v9TMfg/0A6qA2cD57r6p6YC+8yUv1sv4GrJFj59K+X80XXND0wJYsSYVdxiRK26en9PXfGV5VdxhRK5l07yszqpodvIfs5YU1r1yWSQzPuq9InP3+aQrppr6ZuwzEhhZy2OXA2fWsr4RvOtQRKQBSuAneyQvYhERkQz6iCoREammj6gSEZFEU2tRREQkWqrIRESkmlqLIiKSZJbARKbWooiIJJoqMhERCSWxIlMiExGRasnLY2otiohIsqkiExGRkFqLIiKSaElMZGotiohIoqkiExGRUBIrMiUyEREJJTGRqbUoIiKJpopMRESqJa8gU0UmIiLVzCxrt80413+Z2Wwzm2Vmz5pZUzPrbGaTzGyumT1nZoV1HUeJTEREImdmuwBXAz3dvTuQD5wF3Ac85O5dgW+AC+s6lhKZiIiEoqzISL+81czMCoAiYDHQHxgZbB8BDKjrIEpkIiISymYiM7NSM5uScSvdcB53/wp4AFhAOoF9B0wFvnX3ymC3hcAudcWsyR4iIlIv3H0oMLS2bWa2PXAK0Bn4FngBOHZrzqNEJiIioQjfR3YkMM/dlwXnfRE4DGhtZgVBVdYe+KquA6m1KCIi1SyLt01bABxsZkWWzp5HAB8DY4FBwT6DgZfrOpASmYiIRM7dJ5Ge1PEhMJN0PhoK3AhcZ2ZzgR2AP9V1LLUWRUQkFOVHVLn7L4Ff1lj9OXDglhxHiUxEREL6rEUREZGIqSITEZFQEisyJTIREamWvDym1qKIiCSbKjIREQmptdiALXr81LhDiEXTnLnC/6m4eX7cIcQil695y6ZqMm0rJbIGrLyy7n0am6YF0OzwIXGHEYt144fk7DXPxXFDeuxrKzzuMCJX1CR5iSfbciaRiYhI3VSRiYhIoiUxkamhLCIiiaaKTEREqiWvIFMiExGRamotioiIREwVmYiIhJJYkSmRiYhISIlMRESSLXl5TK+RiYhIsqkiExGRkFqLIiKSaElMZGotiohIoqkiExGRUBIrMiUyEREJJTGRqbUoIiKJpopMRESqJa8gUyITEZFqai2KiIhETBWZiIiEkliRKZGJiEgogXlMrUUREUk2VWQiIhJSa1FERBItgXlMrUUREUk2VWQiIhJSa1FERBItgXlMrUUREUk2VWQiIhLKy0teSaZEJiIiIbUWRUREIqaKTEREQkmctaiKrJ5MnDCek084hhOPPYo/PTE07nDq3RWDDmLK8MuZOuJyrjz9YABO7bsnU0dczppxv+THP9o55gjrX65d80y5OvYht91C/8MPZdCAk+IOJWvMsneLylYlMjMbYmbXZysIM3uvIcSRLalUinvuvoM/PPYkL73yOm++8Rr/njs37rDqzZ6d23LBiT3ofckTHPizxzjukB+y2y7FzJ63lLNue453Z3wRd4j1LteueaZcHvtJAwby6GNPxB1GzmsQFZm7Hxp3DNk0a+ZHdOjQkfYdOtCksJBjjz+BcWPHxB1Wvdm9445MnrOQdd9XkEpVMWH6fAYcvgeffrGcz778Ou7wIpFr1zxTLo+9R88DaNWqVdxhZJWZZe0Wlc1KZGZ2npl9ZGYzzOwvNbZdbGaTg22jzKwoWH+6mc0K1o8P1u1lZh+Y2fTgeN2C9aszjnejmc0MHnfvps7RUC0tK2OndjuFy21LSigrK4sxovo1e95SDtunI8Utm9HsB0049uButG/bMu6wIpVr1zxTLo+9MWqUiczM9gJuA/q7+77ANTV2edHdDwi2zQEuDNbfDhwTrD85WHcp8LC77wf0BBbWONdxwCnAQcHjfl3HOTYVd6mZTTGzKUOH5k7PPg6ffrGc3zzzLq/+5qe88sC5zJi7hFSVxx2WiOSIzZm12B94wd2XA7j7ihqZtruZ3QW0BloAfwvWTwSGm9nzwIvBuveBW82sPenk9FmNcx0JDHP3tRvOVcc5NsrdhwIbMpiXV27GSLOkbUkJSxYvCZeXlpVRUlISXQAxGPH6NEa8Pg2AX118BF8tWxlzRNHKxWu+QS6PvTFK4KTFrLxGNhy40t33Bn4FNAVw90tJV3IdgKlmtoO7P0O6OlsHvGFm/bflHA3VXt33ZsGC+Sxc+CUV69fz5huv06ff5g41mdq0bg5Ah7atOOXwPXju7zNjjihauXjNN8jlsTdGSWwtbk5F9g7wkpk96O5fm1lxje3bAYvNrAlwDvAVgJl1cfdJwKSgZdjBzFoBn7v778xsV2Cf4PgbvA3cbmZPu/taMysOqrJaz9FQFRQUcPOtt3NZ6UVUVaUYMPA0unbtFndY9erZO8+guFURFZUprn3odb5bXc7JvXfnwWuOZ8fWRbx439l8NHcJJ1//VNyh1otcvOYb5PLYb7rhOqZOnsy3337DMUf04dLLr2LgaYPiDivnmHvdr2WY2WDgBiAFTAPmA6vd/QEzuwz4BbAMmARs5+7nm9mLQDfAgDHAtcCNwE+BCmAJcHbQqlzt7i2Cc90EnAesB95w91s2cY4hG+KoYwiRthYbiqYF0OzwIXGHEYt144eQq9c8F8cN6bGvrci912aLmmS39PnxHe9k7Zv44e39IynLNiuRNQJKZDlGiSz3KJFlR487x2btmzj1v/tFksgaxPvIREREtpY+a1FEREJJnLWoRCYiIiF9aLCIiEjEVJGJiEgogQWZEpmIiFRTa1FERCRiqshERCSUwIJMiUxERKqptSgiIhIxVWQiIhJKYEGmRCYiItXUWhQREYmYKjIREQklsCBTIhMRkWpqLYqIiERMFZmIiISSWJEpkYmISCiBeUytRRERSTZVZCIiEkpia1EVmYiIhMyyd6v7XNbazEaa2SdmNsfMDjGzYjN728w+C75uX9dxlMhERCRkZlm7bYaHgTfdfXdgX2AOcBMwxt27AWOC5U1SIhMRkciZWSvgcOBPAO6+3t2/BU4BRgS7jQAG1HUsJTIREQlls7VoZqVmNiXjVppxqs7AMmCYmU0zsyfNrDlQ4u6Lg32WACV1xazJHiIiEsrL4mQPdx8KDN3I5gLgx8BV7j7JzB6mRhvR3d3MvK7zqCITEZE4LAQWuvukYHkk6cRWZmbtAIKvS+s6kBKZiIiEopq16O5LgC/N7EfBqiOAj4FXgMHBusHAy3XFrNaiiIiEIn4f2VXA02ZWCHwOXEC6wHrezC4EvgDOqOsgSmQiIhILd58O9Kxl0xFbchwlMhERCeUl74M9lMhERKSaPqJKREQkYjlTkTXNmZH+X+vGD4k7hNjk6jXP1XEDFDVJXjXR0CSwIMudRLa2os731DU6RU0sJ8cN6bF3vf6vcYcRubkPHJfT13z197k39hY/yG7mMZKXydRaFBGRRMuZikxEROqmWYsiIpJomrUoIiISMVVkIiISSmBBpkQmIiLVsvnfuERFrUUREUk0VWQiIhJKYEGmRCYiItU0a1FERCRiqshERCSUwIJMiUxERKpp1qKIiEjEVJGJiEgoefWYEpmIiGTQrEUREZGIqSITEZGQ/hsXERFJNLUWRUREIqaKTEREQgksyJTIRESkmlqLIiIiEVNFJiIiIc1aFBGRRFNrUUREJGKqyEREJJS8ekyJTEREMui/cREREYmYKjIREQklsCBTIhMRkWqatSgiIhIxVWQiIhJKYEGmRFZfhtx2C+PHj6O4eAdGjn417nAik0vj7tymOQ+fu1+4vOsORfz2b59R9l05Vx/dlS5tW3Dq795j1sKV8QUZgVy65pmWLFnM7bfeyIqvv8bMGHjaGZx97nlxh7XNNGsxC8zsWjMrijuObXXSgIE8+tgTcYcRuVwa97xlazj5oYmc/NBEBvx2IuvWp3hr1hL+tWQVl4+YxuR5K+IOMRK5dM0z5efn818/v5GRo19n+FP/ywvPPc3n/54bd1g5qcElMuBaoNZEZmb50Yay9Xr0PIBWrVrFHUbkcnXch3bbkQVfr2XRN+X8e+ka5i1bE3dIkcnVa96mTVv22HMvAJo3b0Hnzl1YurQs5qi2nVn2blHZqkRmZueZ2UdmNsPM/mJmnczsnWDdGDPbNdhvuJkNynjc6uBrXzMbZ2YjzewTM3va0q4GdgbGmtnYDY8xs9+Y2QzgVjMbnXG8o8zspa0fvkh2nLBfO16bvijuMCQmi75ayCefzKH73vvGHco2M7Os3aKyxYnMzPYCbgP6u/u+wDXA74ER7r4P8DTwu8041P6kq689gd2Aw9z9d8AioJ+79wv2aw5MCs51J7C7mbUJtl0A/HlLxyCSTU3yjSP2assbM5bEHYrEYO3aNdxw3dVc/4ubadGiRdzh5KStqcj6Ay+4+3IAd18BHAI8E2z/C9BrM47zgbsvdPcqYDrQaSP7pYBRwbk8OP65ZtY6OO9fa3uQmZWa2RQzmzJ06NDNCEdk6/TZvQ0fL1zJ16vXxx2KRKyiooIbrrua4044if5HHh13OFmRl8VbVOp71mIlwXjMLA8ozNj2fcb91CZiKXf3VMbyMOBVoJx0Qq2s7UHuPhTYkMF8bYVvefQim+HE/drxqtqKOcfdufOXt9G5cxfOPe+CuMPJmlx5Q/Q7wOlmtgOAmRUD7wFnBdvPASYE9+cDPYL7JwNNNuP4q4DtNrbR3ReRbj/eRjqpNUg33XAdg8/5CV/Mn8cxR/ThpVEj4w4pErk27maF+Rz2wx3528zqF/mP6l7Cu7f1Y/+O2/PkhT0ZdnHPGCOsf7l2zTeYPu1DXn/tZSZ/8E9+cvoAfnL6AN6d8I+4w8pJlu7WbeGDzAYDN5CupKYBvySdVHYElgEXuPsCMysBXgaaAW8CV7h7CzPrC1zv7icGx3sEmOLuw83sKuBKYJG79zOz1e7eosb5zwKudfeDNzPknKzIipoYuThuSI+96/W1dp0btbkPHJfT13z197k39hY/yG4Jde3Ln2Ttm/jbU3aPpLzbqtaiu48ARtRY3b+W/cqAzGRzY7B+HDAuY78rM+7/nvTkkQ3Ltb162gvIvTeuiIjUs7zkdRaT98keZjYVWAP8PO5YREQamyS+Rpa4RObuPereS0REckXiEpmIiNQftRZFRCTREthZbJCftSgiIrLZVJGJiEgoif+NixKZiIiEktimS2LMIiIiIVVkIiISSmBnUYlMRESqJfE1MrUWRUQk0VSRiYhIKIEFmRKZiIhUS+Ine6i1KCIiiaaKTEREQkmc7KFEJiIioQTmMbUWRUQk2VSRiYhIKImTPZTIREQkZCQvk6m1KCIiiaaKTEREQmotiohIoiUxkam1KCIiiaZEJiIiITPL2m0zz5dvZtPM7LVgubOZTTKzuWb2nJkV1nUMJTIREQnlWfZum+kaYE7G8n3AQ+7eFfgGuLDOmLd0kCIiItlgZu2BE4Ang2UD+gMjg11GAAPqOo4SmYiIhMyyebNSM5uScSutcbrfAr8AqoLlHYBv3b0yWF4I7FJXzJq1KCIioWx+aLC7DwWG1rbNzE4Elrr7VDPruy3nUSITEZE4HAacbGbHA02BlsDDQGszKwiqsvbAV3UdSK1FEREJRTXZw91vdvf27t4JOAt4x93PAcYCg4LdBgMv1xnzNo1YREQalWy+RraVbgSuM7O5pF8z+1NdD1BrUUREYuXu44Bxwf3PgQO35PFKZCIiEspL4Kff50wiK2qSvIuTDbk6boC5DxwXdwixyOVr3uIHuTv2bEni/xCdM4lsZXlV3Ts1Mi2b5lFeWfd+jVHTAli2OvcG36ZFAc32vzLuMGKxbtojOfl8b5ozv8U3Tt8CEREJJfHT75XIREQklM03REdF0+9FRCTRVJGJiEgogQWZEpmIiFRTa1FERCRiqshERCSUwIJMiUxERKolsU2XxJhFRERCqshERCRkCewtKpGJiEgoeWlMrUUREUk4VWQiIhJK4vvIlMhERCSUvDSm1qKIiCScKjIREQklsLOoRCYiItWSOP1erUUREUk0VWQiIhJKYnWjRCYiIqEkthaVyEREJJS8NJbMKlJERCSkikxEREJqLYqISKIlsU2XxJhFRERCqshERCSk1qKIiCRa8tKYWosiIpJwqshERCSUwM6iEpmIiFTLS2BzUa1FERFJNFVkIiISUmtRAPj+++8pveCnVFSsp7KykiOOOoZLLr8q7rAiM3HCeO67926qUlUMPO10Lry4NO6QIrFq1Uruu/N2Pp87FzPj5l/eSfd99os7rHpzxU/6csGph2JmDHtxIo88Mw6Ay87qwyVn9CZV5bw5YRa3PvxyvIHWo8b4XLcEtha3OZGZWSfgNXfvXmP9HcB4d//7Jh47PHjsyG2NoyEpLCzkj08Oo6ioOZUVFVx0/rkc2qs3ezfiX2obpFIp7rn7Dh5/YhglJSWcfeYg+vbrT5euXeMOrd49fP//46BDenHXr39LRcV6ysvL4w6p3uzZpR0XnHoovX96P+srUrzy6OW8MWEW7Uu258S+e3PgmfeyvqKSNtu3iDvUepPLz/WGpt5eI3P32zeVxBozM6OoqDkAlZWVVFZWJPKvnK0xa+ZHdOjQkfYdOtCksJBjjz+BcWPHxB1WvVu9ahUzpk3lxAGnAdCkSSHbbdcy5qjqz+6dd2LyrPmsK68glapiwtS5DOi/H6Wn9+aBYW+zvqISgGXfrI450vrTWJ/rZtm7RSVbiSzfzJ4ws9lm9paZNTOz4WY2CMDM5pvZr81sppl9YGaZf7IcbmbvmdnnGfubmd1vZrOCx5wZrO9rZuPN7HUz+9TMHjOzBjlhJZVKcfYZAzm6Xy8OOvhQuu+zb9whRWJpWRk7tdspXG5bUkJZWVmMEUVj8aKFtN5+e+4ZcisXnH0a995xO+vWrY07rHoz+9+LOGz/rhS3ak6zpk04ttdetN9pe7p2bMth+3dh/P9cz1tPXkOPPXeNO9R601if63lY1m7RxZwd3YBH3X0v4FvgtFr2+c7d9wYeAX6bsb4d0As4Ebg3WHcqsB+wL3AkcL+ZtQu2HQhcBewJdAn2/Q9mVmpmU8xsytChQ7d6YFsrPz+fZ55/idffGsvsWTOZ+9m/Io9BopNKpfjXJ3MYMOgshj0ziqbNmvHUsCfjDqvefDqvjN8Mf5tX/3AFrzx6BTM+XUgqVUVBfh7FrZpz+HkPcMtDo3nq1z+LO1TJAdlKZPPcfXpwfyrQqZZ9ns34ekjG+tHuXuXuHwMlwbpewLPunnL3MuAfwAHBtg/c/XN3TwXH6lVbQO4+1N17unvP0tL4XoDdrmVLehxwIO+/925sMUSpbUkJSxYvCZeXlpVRUlKyiUc0Dm3altCmbQl77b0PAP2OPJp/fTIn5qjq14jR73PYOb/mqAt/y7cr1/LZF0v5quxbRo+ZDsCU2V9QVeXs2EhfJ2usz/Vcbi1+n3E/Re2TSHwj9zMfuzlD9zqWY/fNihWsWrkSgPLycj745/t06tQ55qiisVf3vVmwYD4LF35Jxfr1vPnG6/Tp1z/usOrdDju2oW3JTiyYPw+AKR/8k067dYk5qvq1YSJHh52255T++/LcX6fw6riP6HPADwHoumtbCpsUsLyRvk7WWJ/rSUxkUU6/P5N06/BM4P069p0AXGJmI4Bi4HDgBmB34EAz6wx8ERwr+r5hHZYvX8aQ226mqipFVVUVRx59LL379Is7rEgUFBRw8623c1npRVRVpRgw8DS6du0Wd1iR+K9f3MKvbruRyooKdt6lPTcPuSvukOrVsw9cRHHr5lRUprj23uf5bvU6Rox+n8eHnMOUF25hfUWKi27/S9xh1ptcfq43NOa+bQVNzen3ZnY90IJ0e/E1dx9pZvOB54DjSFdgP3H3uTWn35vZandvYen/R+DXwf4O3OXuz5lZX+AOYBXQFRgLXO7uVXWE6SvL69ql8WnZNI/yyrijiEfTAli2OvcG36ZFAc32vzLuMGKxbtojOfl8b1qQ3VkVb89ZnrUu11F77BhJXbbNFZm7zwe6Zyw/sJFd73f3G2s89vwayy2Cr066AruhluOsdPcTtyFkERHZiLwEvlOoQU5dFxER2VyRvEbm7p2ydJxxwLhsHEtERP5TEj+8QZ+1KCIioSR+aLBaiyIikmiqyEREJKTWooiIJJpmLYqIiERMFZmIiITUWhQRkUTTrEUREZGIqSITEZFQAgsyJTIREamWl8DeolqLIiKSaKrIREQklLx6TIlMREQyJTCTqbUoIiKJpopMRERCekO0iIgkWgInLaq1KCIiyaaKTEREQgksyJTIREQkQwIzmVqLIiKSaKrIREQkpFmLIiKSaJq1KCIiEjElMhERCVkWb5s8j1kHMxtrZh+b2WwzuyZYX2xmb5vZZ8HX7euKWYlMRESqRZXJoBL4ubvvCRwMXGFmewI3AWPcvRswJljeJCUyERGJnLsvdvcPg/urgDnALsApwIhgtxHAgLqOpckeIiISimPWopl1AvYHJgEl7r442LQEKKnr8arIREQkZJbNm5Wa2ZSMW+l/ns9aAKOAa919ZeY2d3fA64pZFZmIiNQLdx8KDN3YdjNrQjqJPe3uLwary8ysnbsvNrN2wNK6zqOKTEREQhHOWjTgT8Acd38wY9MrwODg/mDg5TpjTldujV5ODFJEclJWX9Sa8eWqrP2+3LfDdhuNzcx6AROAmUBVsPoW0q+TPQ/sCnwBnOHuKzZ1npxpLa6tyL1cVtTEWLEmFXcYsShunp+TYy9unk95ZdxRxKNpAWx35oi6d2xkVj03uO6dtkBUkz3c/V02noSP2JJjqbUoIiKJljMVmYiI1C2Jn7WoRCYiIqEE5jG1FkVEJNlUkYmISLUElmRKZCIiEkrif6yp1qKIiCSaKjIREQlp1qKIiCRaAvOYWosiIpJsqshERKRaAksyJTIREQlp1qKIiEjEVJGJiEhIsxZFRCTREpjH1FoUEZFkU0UmIiLVEliSKZGJiEhIsxZFREQipopMRERCmrUoIiKJlsA8ptaiiIgkmyoyERGplsCSTIlMRERCmrUoIiISMVVkIiIS0qxFERFJtATmMbUWRUQk2VSRiYhItQSWZEpkIiIS0qxFERGRiKkiExGRkGYtSmjIbbcwfvw4iot3YOToV+MOJ1IDTziSoubNyc/LIz+/gGFPvxB3SJHI1XEDTJwwnvvuvZuqVBUDTzudCy8ujTukenPF8XsyuH83HGf2gm+57I/v8uilh/Hj3XagIlXF1LnLufqJ96lMedyhbpUE5rH4E5mZvefuh8YdR7adNGAgZ559Dv99y01xhxKLRx8fTuvtt487jMjl4rhTqRT33H0Hjz8xjJKSEs4+cxB9+/WnS9eucYeWde22L+LS43bngOteprwixYhr+zDo0M48P+FzLvr9BAD+fPXhDO7/Q/709qcxR5s7Yn+NrDEmMYAePQ+gVatWcYchUu9mzfyIDh060r5DB5oUFnLs8ScwbuyYuMOqNwV5eTQrzCc/zygqzGfxN+t4a/pX4fapc5ezS3FRjBFuG7Ps3aISeyIzs9Vm1sLMxpjZh2Y208xOCbZdambTg9s8MxtrZidnrPvUzObFPQb5v8yMa664iPPPHsToUc/HHU5kcnXcS8vK2KndTuFy25ISysrKYoyo/iz+Zi2/e202H/9hEHMfP4Pv1lXwzkeLwu0F+cZZh+/G32d8tYmjNHSWxVs0Ym8tBsqBge6+0sx2BP5pZq+4+2PAY2bWBHgHeNDdXwVeATCz54F/1HZAMysFSgEef/xxzr3g4ijGIcBjf36Ktm1LWLHia6657CI6dtqN/Xv0jDuseper484lrZsXckLPDux95Si+Xbuev/xXX87stRvPvfs5AA9deDAT55Tx3idL4w00x8RekQUMuMfMPgL+DuwClGRsfxh4J0hi6QeY/QJY5+6P1nZAdx/q7j3dvWdpaeN94bkhats2femKi3egT78j+Hj2RzFHFI2cHXdJCUsWLwmXl5aVUVJSsolHJFffvdvxxdLVLF/1PZUp55UPvuCgH7UB4KZB+7Jjy6bc/D+TY45y26i1uPXOAdoAPdx9P6AMaApgZucDHYFfbdjZzI4ETgcujTpQ2bR169ayZs2a8P6kf77Hbl26xRxV/cvVcQPs1X1vFiyYz8KFX1Kxfj1vvvE6ffr1jzuserFw+RoO6NaGZoX5APTt3o5Pv/qOwf27ceQ+O3PBw+PxZE5WDCWvsdhwWoutgKXuXmFm/UgnLsysB3A90Nvdq4J1HYFHgWPcfV1cAdflphuuY+rkyXz77Tccc0QfLr38KgaeNijusOrdiq+/5qafXw1AKlXJ0ceewCGH9Y45qvqXq+MGKCgo4OZbb+ey0ouoqkoxYOBpdO3aOJP4lLnLGT1pPu/eexKVVVXMmLeCYX//F2X/cw4Llq1hzF3HA/DKB19w36jcqMgbAvOY/3wws1VAZ+BVoAUwBTgYOA74JXAMsKHhPAX4ErgKWBisW+Tux9dxGl9bkfA/k7ZCURNjxZpU3GHEorh5fk6Ovbh5PuWVcUcRj6YFsN2ZI+IOI3Krnhuc1eJn8Xfrs/bLsl2rwkgKs1grMjPbAVjh7suBQ2rZ5YKNPPRXG1kvIiLbQJ+1uAXMbGfgfeCBuGIQEZHki60ic/dFwA/jOr+IiNQieQVZg5nsISIiDUAC81iDmX4vIiKyVVSRiYhISP+Ni4iIJJpmLYqIiERMFZmIiFRLXkGmRCYiItUSmMfUWhQRkWRTRSYiIiHNWhQRkURL4qxFJTIREQklsSLTa2QiIpJoSmQiIpJoai2KiEhIrUUREZGIqSITEZGQZi2KiEiiqbUoIiISMVVkIiISSmBBpkQmIiIZEpjJ1FoUEZFEU0UmIiIhzVoUEZFE06xFERGRiKkiExGRUAILMiUyERHJkMBMptaiiIgkmhKZiIiELIv/6jyX2bFm9qmZzTWzm7Y2ZrUWRUQkFNWsRTPLBx4FjgIWApPN7BV3/3hLj6WKTERE4nAgMNfdP3f39cD/AqdszYFypSKzoibxvIJpZqXuPjSWkwPFzfNjOW/c44bcHXvTmH6q4x43wKrnBsdy3oYw9mxpWpC96R5mVgqUZqwamvF92gX4MmPbQuCgrTmPKrL6V1r3Lo1Sro4bcnfsuTpuyO2xb5S7D3X3nhm3ekn2SmQiIhKHr4AOGcvtg3VbTIlMRETiMBnoZmadzawQOAt4ZWsOlCuvkcWpUfTNt0Kujhtyd+y5Om7I7bFvFXevNLMrgb8B+cCf3X321hzL3D2rwYmIiERJrUUREUk0JTIREUk0JbItYGadzGxWLevHmVnPOGKqT2Y2xMyuz+Lx3msIccTBzK41s6K449iUTTy/7zCzI+t47HAzG1R/0cVra5+7Eg0lMomMux8adwwxuhaoNZEFH9XTYLn77e7+97jjiFOOP3cbPCWyLVdgZk+b2RwzG1nzr2wzW51xf5CZDQ/utzGzUWY2ObgdFqzvY2bTg9s0M9su0tFkMLPzzOwjM5thZn+pse3iIO4ZwTiKgvWnm9msYP34YN1eZvZBMKaPzKxbsD7ze3Ojmc0MHnfvps4RlZrjDyqUd4J1Y8xs12C//1N9bBiXmfUNqvORZvZJ8DwxM7sa2BkYa2ZjNzzGzH5jZjOAW81sdMbxjjKzl6Ice4Z8M3vCzGab2Vtm1ixzvGY238x+HVy7D8ysa8ZjDzez98zs84z9zczuD54jM83szGB9XzMbb2avW/pDYx8zswb7+yi4Xi2C58GHwVhOCbZdmvEzPM/MxprZyRnrPjWzeXGPoVFzd9028wZ0Ahw4LFj+M3A9MA7oGaxbnbH/IGB4cP8ZoFdwf1dgTnD/1YzjtQAKYhrbXsC/gB2D5WJgCHB9sLxDxr53AVcF92cCuwT3Wwdffw+cE9wvBJplfm+A44D3gKIN56rjHGEcEY//VWBwsPwzYHRwfzgwKOOxG8bVF/iO9Bs784D3M675/A3HDpYdOCO4b8AnQJuM58pJMT2/K4H9guXngXMzxxuM49bg/nnAaxnfkxeCce9J+jP0AE4D3iY9vboEWAC0C75X5cBuwba3M7+nDe0GrCb9dqWWwfKOwFyCmd/BuibAhJrXLvg+XhH3GBrzrcH+BdSAfenuE4P7TwG9NvNxRwKPmNl00m/6a2lmLYCJwIPBX+2t3b0y2wFvpv7AC+6+HMDdV9TY3t3MJpjZTOAc0r/4IR3/cDO7mPQvJEj/Ar/FzG4EOrr7uhrHOhIY5u5ra5xrY+eIQm3jP4R0UgH4C5t3rT9w94XuXgVMJ50capMCRgXn8uD455pZ6+C8f92qUWy7ee4+Pbg/ldrjfzbj6yEZ60e7e5WnP728JFjXC3jW3VPuXgb8Azgg2PaBpz8wNhUca3N/luJiwD1m9hHwd9KfFViSsf1h4B13fzV8gNkvgHXu/mikkeYYvSF6y9V8492mlptm3M8DDnb38hr732tmrwPHAxPN7Bh3/yQ7oWbVcGCAu88ws/NJ/0WNu19qZgcBJwBTzayHuz9jZpOCdW+Y2SXu/s7WnqMBqiRoywftsMKMbd9n3E+x8Z+x8uAX+AbDSFeA5aQTalx/0NSMv1kt+/hG7mc+dnM+eLaun6WG5hygDdDD3SvMbD7Bz3jwfO0IXLlhZ0tPkDkdODzySHOMKrItt6uZbfgr9Gzg3Rrby8xsj+AX3MCM9W8BV21YMLP9gq9d3H2mu99H+iNbdq+3yDftHeB0M9shiKu4xvbtgMVm1oT0DzTBfl3cfZK73w4sAzqY2W7A5+7+O+BlYJ8ax3obuMCqX2fbcK5azxGR2sb/HumPzSGIZ0Jwfz7QI7h/MumWUl1WkR5frdx9EbAIuI10UmvIzsz4+n4d+04AzjSzfDNrQ/qX+gfBtgMt/fFEecGxav4sNTStgKVBEutHOnFhZj1Iv8RwblCJY2YdSf9fW6fX0pGQLFNFtuU+Ba4wsz8DHwN/BE7K2H4T8BrpX+pTSL/uBXA18GjQligAxgOXAtcGPxRVwGxiaim5+2wzuxv4h5mlgGmkf2Fv8N/AJNLjmkT1L+X7LT2Zw4AxwAzgRuCnZlYBLAHuqXGuN4NEPsXM1gNvALds4hz1biPjvwoYZmY3BDFdEOz+BPByMFHjTWDNZpxiKPCmmS1y934b2edp0q+TzdmWsURg++B5/D3wkzr2fYl0+3EG6YrrF+6+xMx2J/2H2yNAV2BssG9D5aSvz6tB63sK6dc1IV2FFZOezEOw7UtgB2B0sG6Rux8fddC5Qh9RJdJAmNkjwDR3/1PcsWxM0E7rueG1xG04Tl/SE3hOzEJY9Sqo0j90945xxyK1U0Um0gCY2VTSld3P445FqpnZzqRnJT8QcyiyCarIREQk0TTZQ0REEk2JTEREEk2JTEREEk2JTEREEk2JTEREEu3/AwyI4bPd/v3cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classes=['blues', 'classical', 'country','hiphop', 'jazz']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,7))         # Sample figsize in inches\n",
    "sns.heatmap(cf_matrix, annot=True , cmap='Blues',xticklabels=classes,yticklabels=classes,linewidth=1,linecolor='w',ax=ax)\n",
    "plt.yticks(rotation=0) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
